"""
PASSO 1: Upload do modelo para Vertex AI Model Registry
=========================================================
Este script pega o modelo treinado e registra no Vertex AI.
"""

import os
import sys
import joblib
import shutil
import pickle
from google.cloud import aiplatform
from google.cloud import storage

# Configura√ß√µes
PROJECT_ID = "mlops-484912"
REGION = "us-central1"
BUCKET_NAME = "meu-bucket-29061999"
MODEL_DISPLAY_NAME = "modelo-inadimplencia-gcp"

# Paths
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_DIR = os.path.dirname(SCRIPT_DIR)
MLRUNS_DIR = os.path.join(PROJECT_DIR, "mlruns")

# Adicionar src ao path
sys.path.append(os.path.join(PROJECT_DIR, "src"))


def find_latest_model():
    """Encontra o modelo mais recente no MLflow"""
    import mlflow
    import pandas as pd
    
    # Tentar diferentes caminhos poss√≠veis
    possible_paths = [
        MLRUNS_DIR,
        os.path.join(PROJECT_DIR, "mlruns"),
        "./mlruns",
        "/content/MLFlow-GCP/mlruns",
    ]
    
    mlruns_path = None
    for path in possible_paths:
        if os.path.exists(path):
            mlruns_path = path
            print(f"   ‚úÖ Encontrado mlruns em: {path}")
            break
        else:
            print(f"   ‚ùå N√£o existe: {path}")
    
    if not mlruns_path:
        raise Exception("Pasta mlruns n√£o encontrada!")
    
    mlflow.set_tracking_uri(mlruns_path)
    
    # Listar conte√∫do do mlruns para debug
    print(f"\n   üìÇ Conte√∫do de {mlruns_path}:")
    for item in os.listdir(mlruns_path):
        item_path = os.path.join(mlruns_path, item)
        if os.path.isdir(item_path):
            print(f"      üìÅ {item}/")
        else:
            print(f"      üìÑ {item}")
    
    # Buscar todos os experiments
    try:
        experiments = mlflow.search_experiments()
        print(f"\n   üî¨ Experiments encontrados: {len(experiments)}")
        for exp in experiments:
            print(f"      - {exp.name} (ID: {exp.experiment_id})")
    except Exception as e:
        print(f"   ‚ö†Ô∏è Erro ao buscar experiments: {e}")
        experiments = []
    
    # Buscar runs em cada experiment
    all_runs = []
    for exp in experiments:
        try:
            runs = mlflow.search_runs(experiment_ids=[exp.experiment_id])
            if not runs.empty:
                print(f"   üìä Experiment '{exp.name}': {len(runs)} runs")
                all_runs.append(runs)
        except Exception as e:
            print(f"   ‚ö†Ô∏è Erro no experiment {exp.name}: {e}")
    
    # Se n√£o encontrou via API, tentar buscar diretamente nos diret√≥rios
    if not all_runs:
        print("\n   üîç Buscando modelos diretamente nos diret√≥rios...")
        
        # Procurar em subpastas do mlruns
        for item in os.listdir(mlruns_path):
            exp_path = os.path.join(mlruns_path, item)
            if os.path.isdir(exp_path) and item not in ['.trash', 'models']:
                # Listar runs
                for run_item in os.listdir(exp_path):
                    run_path = os.path.join(exp_path, run_item)
                    if os.path.isdir(run_path) and run_item != 'meta.yaml':
                        artifacts_path = os.path.join(run_path, "artifacts")
                        if os.path.exists(artifacts_path):
                            # Procurar modelo
                            for root, dirs, files in os.walk(artifacts_path):
                                for file in files:
                                    if file.endswith(('.pkl', '.joblib')):
                                        model_path = os.path.join(root, file)
                                        print(f"   ‚úÖ Modelo encontrado: {model_path}")
                                        return model_path, run_item, 0.85  # accuracy padr√£o
    
    if not all_runs:
        raise Exception("Nenhum run encontrado no MLflow!")
    
    # Concatenar todos os runs e pegar o melhor
    all_runs_df = pd.concat(all_runs, ignore_index=True)
    
    # Verificar se tem coluna accuracy
    if 'metrics.accuracy' in all_runs_df.columns:
        all_runs_df = all_runs_df.sort_values("metrics.accuracy", ascending=False)
        accuracy = all_runs_df.iloc[0].get("metrics.accuracy", 0)
    else:
        accuracy = 0.85  # valor padr√£o
    
    best_run = all_runs_df.iloc[0]
    run_id = best_run["run_id"]
    experiment_id = best_run["experiment_id"]
    f1 = best_run.get("metrics.f1_score", 0)
    
    print(f"\n‚úÖ Melhor modelo encontrado:")
    print(f"   Run ID: {run_id}")
    print(f"   Experiment ID: {experiment_id}")
    print(f"   Accuracy: {accuracy:.4f}")
    if pd.notna(f1):
        print(f"   F1-Score: {f1:.4f}")
    
    # Encontrar o arquivo do modelo
    artifacts_dir = os.path.join(mlruns_path, str(experiment_id), run_id, "artifacts")
    
    print(f"\n   üîç Buscando modelo em: {artifacts_dir}")
    
    # Procurar pelo modelo
    model_path = None
    for root, dirs, files in os.walk(artifacts_dir):
        for file in files:
            if file.endswith(('.pkl', '.joblib')) or file == 'model.pkl':
                model_path = os.path.join(root, file)
                print(f"   ‚úÖ Arquivo encontrado: {model_path}")
                break
        if model_path:
            break
    
    if not model_path:
        # Tentar carregar via MLflow com diferentes nomes de artifact
        artifact_names = ["model", "model_rfc", "model_xgb"]
        
        for artifact_name in artifact_names:
            model_uri = f"runs:/{run_id}/{artifact_name}"
            print(f"   üîÑ Tentando carregar via URI: {model_uri}")
            try:
                model = mlflow.sklearn.load_model(model_uri)
                # Salvar temporariamente
                import joblib
                temp_path = os.path.join(PROJECT_DIR, "temp_model.pkl")
                joblib.dump(model, temp_path)
                model_path = temp_path
                print(f"   ‚úÖ Modelo carregado via MLflow URI: {artifact_name}")
                break
            except Exception as e:
                print(f"   ‚ö†Ô∏è N√£o encontrado: {artifact_name}")
                continue
        
        if not model_path:
            # Tentar com xgboost
            for artifact_name in artifact_names:
                model_uri = f"runs:/{run_id}/{artifact_name}"
                try:
                    model = mlflow.xgboost.load_model(model_uri)
                    import joblib
                    temp_path = os.path.join(PROJECT_DIR, "temp_model.pkl")
                    joblib.dump(model, temp_path)
                    model_path = temp_path
                    print(f"   ‚úÖ Modelo XGBoost carregado via: {artifact_name}")
                    break
                except:
                    continue
        
        if not model_path:
            raise Exception(f"N√£o foi poss√≠vel encontrar o modelo para run {run_id}")
    
    return model_path, run_id, accuracy


def prepare_model_for_vertex(model_path, output_dir):
    """
    Prepara o modelo no formato que o Vertex AI espera.
    Vertex AI precisa de um diret√≥rio com model.pkl
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # Copiar modelo
    dest_path = os.path.join(output_dir, "model.pkl")
    shutil.copy(model_path, dest_path)
    
    print(f"‚úÖ Modelo preparado em: {output_dir}")
    return output_dir


def upload_to_gcs(local_dir, gcs_path):
    """Faz upload do modelo para o GCS"""
    storage_client = storage.Client(project=PROJECT_ID)
    bucket = storage_client.bucket(BUCKET_NAME)
    
    for root, dirs, files in os.walk(local_dir):
        for file in files:
            local_path = os.path.join(root, file)
            blob_path = f"{gcs_path}/{file}"
            blob = bucket.blob(blob_path)
            blob.upload_from_filename(local_path)
            print(f"‚úÖ Uploaded: gs://{BUCKET_NAME}/{blob_path}")
    
    return f"gs://{BUCKET_NAME}/{gcs_path}"


def register_model_in_vertex(artifact_uri, model_name, accuracy):
    """Registra o modelo no Vertex AI Model Registry"""
    
    # Inicializar Vertex AI
    aiplatform.init(project=PROJECT_ID, location=REGION)
    
    # Upload do modelo
    # Usando container de sklearn pr√©-constru√≠do
    model = aiplatform.Model.upload(
        display_name=model_name,
        artifact_uri=artifact_uri,
        serving_container_image_uri="us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-3:latest",
        description=f"Modelo de predi√ß√£o de inadimpl√™ncia. Accuracy: {accuracy:.4f}",
        labels={
            "task": "classification",
            "framework": "sklearn",
            "accuracy": str(round(accuracy, 4)).replace(".", "_")
        }
    )
    
    print(f"\nüéâ Modelo registrado no Vertex AI!")
    print(f"   Model Resource Name: {model.resource_name}")
    print(f"   Model ID: {model.name}")
    
    return model


def main():
    print("=" * 60)
    print("üöÄ UPLOAD DO MODELO PARA VERTEX AI MODEL REGISTRY")
    print("=" * 60)
    
    # 1. Encontrar o melhor modelo
    print("\nüìå Passo 1: Encontrando o melhor modelo...")
    model_path, run_id, accuracy = find_latest_model()
    print(f"   Modelo encontrado: {model_path}")
    
    # 2. Preparar modelo
    print("\nüìå Passo 2: Preparando modelo para Vertex AI...")
    temp_dir = os.path.join(PROJECT_DIR, "temp_model_vertex")
    prepare_model_for_vertex(model_path, temp_dir)
    
    # 3. Upload para GCS
    print("\nüìå Passo 3: Fazendo upload para GCS...")
    gcs_path = f"models/inadimplencia/{run_id}"
    artifact_uri = upload_to_gcs(temp_dir, gcs_path)
    
    # 4. Registrar no Vertex AI
    print("\nüìå Passo 4: Registrando no Vertex AI Model Registry...")
    model = register_model_in_vertex(artifact_uri, MODEL_DISPLAY_NAME, accuracy)
    
    # Limpar temp
    shutil.rmtree(temp_dir, ignore_errors=True)
    if os.path.exists(os.path.join(PROJECT_DIR, "temp_model.pkl")):
        os.remove(os.path.join(PROJECT_DIR, "temp_model.pkl"))
    
    print("\n" + "=" * 60)
    print("‚úÖ MODELO REGISTRADO COM SUCESSO!")
    print("=" * 60)
    print(f"\nPr√≥ximo passo: Execute 02_deploy_endpoint.py para criar o endpoint")
    
    # Salvar model resource name para o pr√≥ximo script
    with open(os.path.join(SCRIPT_DIR, ".model_resource_name"), "w") as f:
        f.write(model.resource_name)
    
    return model


if __name__ == "__main__":
    main()
